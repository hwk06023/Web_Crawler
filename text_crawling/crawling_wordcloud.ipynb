{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Warning: Failed to create the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색어 지정\n",
    "search_text = '카카오 데이터 센터'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"MjjYud\" - class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카카오 데이터 센터 - Google 검색\n",
      "['https://www.kakaocorp.com/page/detail/9385', 'https://www.google.com/search?sca_esv=562982649&q=%EC%B9%B4%EC%B9%B4%EC%98%A4+%EB%8D%B0%EC%9D%B4%ED%84%B0+%EC%84%BC%ED%84%B0&tbm=isch&source=univ&fir=I_uMblBBGD3m6M%252Cdc1lduNyi3V5vM%252C_%253BMWpRQvbVUe7GEM%252C4WIY3csiTS5-sM%252C_%253BZMJLb4xkUAvywM%252CN1I0xFwExSSbtM%252C_%253BhMLsdF2C80THcM%252CP_hrrvRxHdS88M%252C_%253BqHddRJgXMzhfHM%252Cpda4kDdHgRaqFM%252C_%253BWmRHSm9UKpdZ7M%252C-jW2QjXh6yeTsM%252C_%253BdXybTr-PUicCmM%252CMQ-ZSJ2ENaMBYM%252C_%253BSN4lrBOUprbZUM%252CJzIZySqH_tPrrM%252C_%253BMfK8HMd9ARtKiM%252CxaSuY1pIJJIUHM%252C_%253BPlfadBUXm8Zr8M%252Cfnd5OKtv_BZRNM%252C_&usg=AI4_-kSL1X_tinN1chOjugADOc7dQ7guIA&sa=X&ved=2ahUKEwiA_YivopWBAxXcplYBHZeIDaUQjJkEegQIFRAC', 'https://www.kakaoicloud.com/service/detail/10-27', 'https://www.yna.co.kr/view/AKR20211217076900061', 'https://www.etnews.com/20221104000073', 'https://www.chosun.com/economy/industry-company/2023/06/26/H23QVJGG6ZCTJFKJZKQJCDY4WI/', 'http://www.investchosun.com/site/data/html_dir/2022/10/19/2022101980182.html', 'https://zdnet.co.kr/view/?no=20221016114830']\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.google.com/search?q='+ search_text)\n",
    "\n",
    "print(driver.title)\n",
    "\n",
    "html = driver.page_source \n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "\n",
    "link_list = []\n",
    "for i in range(2, 10):\n",
    "    a = driver.find_element(By.XPATH, '//*[@id=\"rso\"]/div['+str(i)+']')\n",
    "    link_list.append(a.find_element(By.TAG_NAME, 'a').get_attribute('href'))\n",
    "\n",
    "print(link_list)\n",
    "createDirectory('./finded_'+ search_text)\n",
    "\n",
    "# 검색 결과 페이지에서 하나씩 열어서 내용 전부 크롤링\n",
    "\n",
    "p_num = 0\n",
    "for link in link_list:\n",
    "    driver.get(link)\n",
    "    html = driver.page_source \n",
    "    soup = BeautifulSoup(html, 'html.parser') \n",
    "    f = open('./finded_'+ search_text +'/' + str(p_num) + '.txt', 'w', encoding='utf-8')\n",
    "    f.write(soup.text)\n",
    "    p_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwordcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m WordCloud\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkonlpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtag\u001b[39;00m \u001b[39mimport\u001b[39;00m Twitter\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Counter\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "from konlpy.tag import Twitter\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting WordCloud\n",
      "  Using cached wordcloud-1.9.2.tar.gz (222 kB)\n",
      "Collecting numpy>=1.6.1\n",
      "  Using cached numpy-1.24.4.tar.gz (10.9 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pillow\n",
      "  Using cached Pillow-10.0.0.tar.gz (50.5 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Using cached matplotlib-3.7.2.tar.gz (38.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
      "  Using cached importlib_resources-6.0.1-py3-none-any.whl (34 kB)\n",
      "Collecting pyparsing<3.1,>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.42.1-py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kimhyunwoo/.pyenv/versions/3.8.6/lib/python3.8/site-packages (from matplotlib->WordCloud) (23.1)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.1.0.tar.gz (13.4 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kimhyunwoo/.pyenv/versions/3.8.6/lib/python3.8/site-packages (from matplotlib->WordCloud) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.5.tar.gz (97 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /Users/kimhyunwoo/.pyenv/versions/3.8.6/lib/python3.8/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib->WordCloud) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kimhyunwoo/.pyenv/versions/3.8.6/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->WordCloud) (1.16.0)\n",
      "Using legacy 'setup.py install' for WordCloud, since package 'wheel' is not installed.\n",
      "Building wheels for collected packages: numpy, pillow, matplotlib, contourpy, kiwisolver\n",
      "  Building wheel for numpy (PEP 517) ... \u001b[?25l|"
     ]
    }
   ],
   "source": [
    "!pip3 install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir('./finded_'+ search_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('finded_'+ search_text +'.txt', 'w') as outfile:\n",
    "    for filename in filenames:\n",
    "        with open(filename) as file:\n",
    "            outfile.write(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('finded_'+ search_text +'.txt').read() \n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "sentences_tag = []\n",
    "sentences_tag = twitter.pos(text) \n",
    "\n",
    "noun_adj_list = []\n",
    "\n",
    "for word, tag in sentences_tag:\n",
    "    if tag in ['Noun' , 'Adjective']: \n",
    "        noun_adj_list.append(word)\n",
    "\n",
    "counts = Counter(noun_adj_list)\n",
    "tags = counts.most_common(20) \n",
    "\n",
    "wc = WordCloud(font_path=[\"/Users/kimhyunwoo/Library/Fonts/Na\"],background_color=\"white\", max_font_size=60)\n",
    "cloud = wc.generate_from_frequencies(dict(tags))\n",
    "\n",
    "\n",
    "cloud.to_file('test.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
